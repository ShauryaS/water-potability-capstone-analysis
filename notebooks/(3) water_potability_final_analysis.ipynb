{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Potability Machine Learning Final Classifiers and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_potability_data = pd.read_csv('../data/waterpotability.csv')\n",
    "water_potability_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_potability_cleaned_data = water_potability_data.copy()\n",
    "water_potability_cleaned_data['ph'] = water_potability_cleaned_data['ph'].fillna(water_potability_cleaned_data['ph'].mean())\n",
    "water_potability_cleaned_data['Sulfate'] = water_potability_cleaned_data['Sulfate'].fillna(water_potability_cleaned_data['Sulfate'].mean())\n",
    "water_potability_cleaned_data['Trihalomethanes'] = water_potability_cleaned_data['Trihalomethanes'].fillna(water_potability_cleaned_data['Trihalomethanes'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = water_potability_cleaned_data.drop('Potability', axis=1)\n",
    "y = water_potability_cleaned_data['Potability']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=142, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Data Imbalance Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random undersampling\n",
    "def undersample(X, y):\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
    "    return X_undersampled, y_undersampled\n",
    "\n",
    "# random oversampling\n",
    "def oversample(X, y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_oversampled, y_oversampled = ros.fit_resample(X, y)\n",
    "    return X_oversampled, y_oversampled\n",
    "\n",
    "# smote\n",
    "def smote(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_smoted, y_smoted = smote.fit_resample(X, y)\n",
    "    return X_smoted, y_smoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scorer\n",
    "def get_scorer(scorer='none'):\n",
    "    if scorer == 'accuracy':\n",
    "        return make_scorer(accuracy_score)\n",
    "    elif scorer == 'precision':\n",
    "        return make_scorer(precision_score, pos_label=1)\n",
    "    elif scorer == 'recall':\n",
    "        return make_scorer(recall_score, pos_label=1)\n",
    "    elif scorer == 'f1':\n",
    "        return make_scorer(f1_score, pos_label=1)\n",
    "    elif scorer == 'roc_auc':\n",
    "        return make_scorer(roc_auc_score)\n",
    "    else:\n",
    "        return make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classifier prefix\n",
    "def get_classifier_prefix(classifier):\n",
    "    if classifier == 'Logistic Regression':\n",
    "        return 'lgr'\n",
    "    elif classifier == 'KNN':\n",
    "        return 'knn'\n",
    "    elif classifier == 'SVM':\n",
    "        return 'svm'\n",
    "    elif classifier == 'Decision Tree':\n",
    "        return 'dt'\n",
    "    elif classifier == 'Random Forest':\n",
    "        return 'rf'\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "def sample(X_train, y_train, sampling_method='none'):\n",
    "    if sampling_method == 'under':\n",
    "        return undersample(X_train, y_train)\n",
    "    elif sampling_method == 'over':\n",
    "        return oversample(X_train, y_train)\n",
    "    elif sampling_method == 'smote':\n",
    "        return smote(X_train, y_train)\n",
    "    else:\n",
    "        return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model pipeline methods\n",
    "\n",
    "def get_classifier_pipeline(classifier):\n",
    "    if classifier == 'Logistic Regression':\n",
    "        return get_lgr_pipeline()\n",
    "    elif classifier == 'KNN':\n",
    "        return get_knn_pipeline()\n",
    "    elif classifier == 'SVM':\n",
    "        return get_svm_pipeline()\n",
    "    elif classifier == 'Decision Tree':\n",
    "        return get_dt_pipeline()\n",
    "    elif classifier == 'Random Forest':\n",
    "        return get_rf_pipeline()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_lgr_pipeline():\n",
    "    extractor = SelectFromModel(LogisticRegression(penalty='l1', solver = 'liblinear', random_state = 42))\n",
    "    return Pipeline([('scaler', StandardScaler()),\n",
    "                    ('selector', extractor),\n",
    "                    ('lgr', LogisticRegression(random_state=42, max_iter = 1000))])\n",
    "\n",
    "def get_knn_pipeline():\n",
    "    return Pipeline([('scaler', StandardScaler()),\n",
    "                    ('knn', KNeighborsClassifier())])\n",
    "\n",
    "def get_svm_pipeline():\n",
    "    return Pipeline([('scaler', StandardScaler()),\n",
    "                    ('svm', SVC(probability=False))])\n",
    "\n",
    "def get_dt_pipeline():\n",
    "    return Pipeline([('dt', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "def get_rf_pipeline():\n",
    "    return Pipeline([('scaler', StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyperparameters\n",
    "\n",
    "def get_hyperparameters(classifier):\n",
    "    if classifier == 'Logistic Regression':\n",
    "        return get_lgr_hyperparameters()\n",
    "    elif classifier == 'KNN':\n",
    "        return get_knn_hyperparameters()\n",
    "    elif classifier == 'SVM':\n",
    "        return get_svm_hyperparameters()\n",
    "    elif classifier == 'Decision Tree':\n",
    "        return get_dt_hyperparameters()\n",
    "    elif classifier == 'Random Forest':\n",
    "        return get_rf_hyperparameters()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_lgr_hyperparameters():\n",
    "    return { \n",
    "        'lgr__C': [0.001, 0.01, 0.1, 1, 10, 100] \n",
    "    }\n",
    "\n",
    "def get_knn_hyperparameters():\n",
    "    return {\n",
    "        'knn__n_neighbors': [n for n in range(1,22,2)],\n",
    "        'knn__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "def get_svm_hyperparameters():\n",
    "    return {\n",
    "        'svm__C': [0.1, 1, 10],\n",
    "        'svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'svm__gamma': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "def get_dt_hyperparameters():\n",
    "    return {\n",
    "        'dt__max_depth': range(1,11,2),\n",
    "        'dt__min_samples_split': [2,3,4,5],\n",
    "        'dt__min_samples_leaf': [1,2,3,4,5],\n",
    "        'dt__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "def get_rf_hyperparameters():\n",
    "    return {\n",
    "        'rf__n_estimators': [100, 150, 200, 300],\n",
    "        'rf__max_depth': [10, 20, 30],\n",
    "        'rf__min_samples_split': [2,5,10],\n",
    "        'rf__min_samples_leaf': [1,2,4],\n",
    "        'rf__criterion': ['gini', 'entropy']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_classifier(classifier, X_train, y_train, X_test, y_test, scorer, sampling_method, halving_search=False):\n",
    "    gs = None\n",
    "    gs_path = '../models/' + get_classifier_prefix(classifier) + '_gs_' + sampling_method + '_' + scorer + '_' + '.pkl'\n",
    "\n",
    "    if os.path.exists(gs_path):\n",
    "        gs = joblib.load(gs_path)\n",
    "    else:\n",
    "        X_train_sampled, y_train_sampled = sample(X_train, y_train, sampling_method)\n",
    "        scorer = get_scorer(scorer)\n",
    "\n",
    "        pipe = get_classifier_pipeline(classifier)\n",
    "        params = get_hyperparameters(classifier)\n",
    "\n",
    "        if halving_search:\n",
    "            gs = HalvingGridSearchCV(pipe, param_grid=params, cv=5, scoring=scorer, n_jobs=5)\n",
    "        else:\n",
    "            gs = GridSearchCV(pipe, param_grid=params, cv=5, scoring=scorer, n_jobs=5)\n",
    "\n",
    "        gs.fit(X_train_sampled, y_train_sampled)\n",
    "        joblib.dump(gs, gs_path)\n",
    "\n",
    "    train_score = gs.best_score_\n",
    "    test_score = gs.score(X_test, y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, gs.predict(X_test))\n",
    "    precision = precision_score(y_test, gs.predict(X_test))\n",
    "    recall = recall_score(y_test, gs.predict(X_test))\n",
    "    f1 = f1_score(y_test, gs.predict(X_test))\n",
    "    roc_auc = roc_auc_score(y_test, gs.predict(X_test))\n",
    "\n",
    "    best_params = gs.best_params_\n",
    "\n",
    "    return train_score, test_score, accuracy, precision, recall, f1, roc_auc, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the results dict with the classifier results\n",
    "def update_results(results, classifier, sampling, scorer, train_score, test_score, accuracy, precision, recall, f1, roc_auc, best_params):\n",
    "    results['model'].append(classifier)\n",
    "    results['sampling'].append(sampling)\n",
    "    results['scorer'].append(scorer)\n",
    "    results['train_score'].append(train_score)\n",
    "    results['test_score'].append(test_score)\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['precision'].append(precision)\n",
    "    results['recall'].append(recall)\n",
    "    results['f1'].append(f1)\n",
    "    results['roc_auc'].append(roc_auc)\n",
    "    results['best_params'].append(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifier Executions completed: 100%|██████████| 100/100 [00:10<00:00,  9.33it/s]                                      \n"
     ]
    }
   ],
   "source": [
    "classifiers = ['Logistic Regression', 'KNN', 'Decision Tree', 'SVM', 'Random Forest']\n",
    "samplings = ['none', 'under', 'over', 'smote']\n",
    "scorers = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "useHalvingSearch = ['SVM']\n",
    "\n",
    "results = {'model': [], 'sampling': [], 'scorer': [], 'train_score': [], 'test_score': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'roc_auc': [], 'best_params': []}\n",
    "\n",
    "total_iterations = len(classifiers) * len(samplings) * len(scorers)\n",
    "\n",
    "with tqdm(total=total_iterations) as progress_bar:\n",
    "    for classifier in classifiers:\n",
    "        for sampling in samplings:\n",
    "            for scorer in scorers:\n",
    "                progress_bar.set_description(f'Executing {classifier} with {sampling} sampling and {scorer} scorer')\n",
    "                halvingSearch = classifier in useHalvingSearch\n",
    "                train_score, test_score, accuracy, precision, recall, f1, roc_auc, best_params = execute_classifier(classifier, X_train, y_train, X_test, y_test, scorer, sampling, halvingSearch)\n",
    "                update_results(results, classifier, sampling, scorer, train_score, test_score, accuracy, precision, recall, f1, roc_auc, best_params)\n",
    "                progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description('Classifier Executions completed')\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Scores of All the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sampling</th>\n",
       "      <th>scorer</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.679541</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.581484</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.791320</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.791221</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.680534</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.391421</td>\n",
       "      <td>0.587578</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.413356</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.650915</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.592812</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.494267</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.650915</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.592812</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.793344</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.650915</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.473563</td>\n",
       "      <td>0.606172</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>under</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.655839</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>0.649390</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.522822</td>\n",
       "      <td>0.621094</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KNN</td>\n",
       "      <td>none</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.624408</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.329480</td>\n",
       "      <td>0.570078</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.797093</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.644817</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.438554</td>\n",
       "      <td>0.592734</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.696007</td>\n",
       "      <td>0.533066</td>\n",
       "      <td>0.644817</td>\n",
       "      <td>0.547325</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.533066</td>\n",
       "      <td>0.622266</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>none</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.749144</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.643293</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.559141</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.651908</td>\n",
       "      <td>0.641768</td>\n",
       "      <td>0.641768</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.352617</td>\n",
       "      <td>0.571250</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNN</td>\n",
       "      <td>none</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.586472</td>\n",
       "      <td>0.571250</td>\n",
       "      <td>0.641768</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.352617</td>\n",
       "      <td>0.571250</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.784080</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.641768</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.592344</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>SVM</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.655573</td>\n",
       "      <td>0.640244</td>\n",
       "      <td>0.640244</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SVM</td>\n",
       "      <td>over</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.630907</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.640244</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.716992</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.640244</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.616406</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.637195</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.571719</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>none</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.462250</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.637195</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.571719</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>none</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.620489</td>\n",
       "      <td>0.571719</td>\n",
       "      <td>0.637195</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.571719</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.707775</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.534979</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.521042</td>\n",
       "      <td>0.612656</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.707703</td>\n",
       "      <td>0.612656</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.534979</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.521042</td>\n",
       "      <td>0.612656</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>under</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.626716</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.549906</td>\n",
       "      <td>0.623906</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>under</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.613501</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.549906</td>\n",
       "      <td>0.623906</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>under</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.621883</td>\n",
       "      <td>0.549906</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.549906</td>\n",
       "      <td>0.623906</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>under</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.626719</td>\n",
       "      <td>0.623906</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.549906</td>\n",
       "      <td>0.623906</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.688873</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631098</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.514056</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SVM</td>\n",
       "      <td>under</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.618369</td>\n",
       "      <td>0.604453</td>\n",
       "      <td>0.626524</td>\n",
       "      <td>0.522267</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.512922</td>\n",
       "      <td>0.604453</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>SVM</td>\n",
       "      <td>smote</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.645840</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.514754</td>\n",
       "      <td>0.613281</td>\n",
       "      <td>0.559715</td>\n",
       "      <td>0.621641</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>SVM</td>\n",
       "      <td>under</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.619576</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.478992</td>\n",
       "      <td>0.590156</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SVM</td>\n",
       "      <td>under</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.533943</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.478992</td>\n",
       "      <td>0.590156</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNN</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.737816</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.602812</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KNN</td>\n",
       "      <td>over</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.699669</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.602812</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KNN</td>\n",
       "      <td>over</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.754461</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.602812</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>KNN</td>\n",
       "      <td>over</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.737740</td>\n",
       "      <td>0.602812</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.602812</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.324754</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.543359</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>none</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.410534</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.543359</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.646565</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.207031</td>\n",
       "      <td>0.297753</td>\n",
       "      <td>0.544766</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 9, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>none</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.583459</td>\n",
       "      <td>0.544922</td>\n",
       "      <td>0.617378</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.214844</td>\n",
       "      <td>0.304709</td>\n",
       "      <td>0.544922</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 4, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.611832</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>none</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>none</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>none</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.503507</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.504758</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>0.611280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>{'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>none</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.690488</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.611280</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.511797</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 3, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SVM</td>\n",
       "      <td>smote</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.551125</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>0.534545</td>\n",
       "      <td>0.603359</td>\n",
       "      <td>{'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SVM</td>\n",
       "      <td>smote</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.663116</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>0.600547</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SVM</td>\n",
       "      <td>smote</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.694003</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>0.600547</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>over</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.829034</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.518797</td>\n",
       "      <td>0.597031</td>\n",
       "      <td>{'knn__n_neighbors': 13, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.617962</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>0.561172</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>over</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.481781</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>0.561172</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>over</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.554950</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>0.561172</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>over</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.617921</td>\n",
       "      <td>0.561172</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>0.561172</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>SVM</td>\n",
       "      <td>over</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 10.0, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>under</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.423678</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>0.605183</td>\n",
       "      <td>0.492147</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>0.420582</td>\n",
       "      <td>0.562344</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 3, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>under</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.486509</td>\n",
       "      <td>0.420582</td>\n",
       "      <td>0.605183</td>\n",
       "      <td>0.492147</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>0.420582</td>\n",
       "      <td>0.562344</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 3, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SVM</td>\n",
       "      <td>over</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.694001</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.602134</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.264789</td>\n",
       "      <td>0.526797</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>SVM</td>\n",
       "      <td>over</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.757012</td>\n",
       "      <td>0.526797</td>\n",
       "      <td>0.602134</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.264789</td>\n",
       "      <td>0.526797</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNN</td>\n",
       "      <td>under</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.601777</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.578984</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>under</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.616656</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.578984</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNN</td>\n",
       "      <td>under</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.574503</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.578984</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNN</td>\n",
       "      <td>under</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.601808</td>\n",
       "      <td>0.578984</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.578984</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KNN</td>\n",
       "      <td>smote</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.767175</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.599085</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.539405</td>\n",
       "      <td>0.599531</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>under</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.562119</td>\n",
       "      <td>0.596037</td>\n",
       "      <td>0.596037</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 7, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>under</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.562152</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.596037</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 7, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>KNN</td>\n",
       "      <td>smote</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.689308</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490421</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KNN</td>\n",
       "      <td>smote</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.662917</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490421</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>smote</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.710226</td>\n",
       "      <td>0.490421</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490421</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>KNN</td>\n",
       "      <td>smote</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.689269</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490421</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SVM</td>\n",
       "      <td>smote</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>0.531797</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>0.463235</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.531797</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 1.0, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>under</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.717972</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.591463</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.167702</td>\n",
       "      <td>0.503984</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 1, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>over</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.726401</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.586890</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.422175</td>\n",
       "      <td>0.550859</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KNN</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.462846</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNN</td>\n",
       "      <td>none</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.474962</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.598259</td>\n",
       "      <td>0.577744</td>\n",
       "      <td>0.577744</td>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.608493</td>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.577744</td>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.581752</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.577744</td>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.598309</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>0.577744</td>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNN</td>\n",
       "      <td>under</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.556738</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571646</td>\n",
       "      <td>0.455516</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.476723</td>\n",
       "      <td>0.558750</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.379467</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.412639</td>\n",
       "      <td>0.503047</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SVM</td>\n",
       "      <td>under</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.524566</td>\n",
       "      <td>0.376033</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.376033</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.365462</td>\n",
       "      <td>0.488984</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>under</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.506363</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>{'lgr__C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>under</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.508231</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>{'lgr__C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>under</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.480473</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>{'lgr__C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>under</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.493492</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>{'lgr__C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>under</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.506413</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>{'lgr__C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.503123</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.384365</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.419183</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.502888</td>\n",
       "      <td>0.384365</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.384365</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.419183</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.478064</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.384365</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.419183</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.490084</td>\n",
       "      <td>0.419183</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.384365</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.419183</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.503108</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.384365</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.419183</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SVM</td>\n",
       "      <td>under</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.483935</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.389222</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.507506</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>{'lgr__C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>over</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.507809</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>{'lgr__C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>over</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.484975</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>{'lgr__C': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>over</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.496022</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>{'lgr__C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>over</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.507504</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>{'lgr__C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.577719</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.472561</td>\n",
       "      <td>0.416045</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.563131</td>\n",
       "      <td>0.544297</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 3, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model sampling     scorer  train_score  test_score  \\\n",
       "60                  SVM     none   accuracy     0.679541    0.658537   \n",
       "90        Random Forest     over   accuracy     0.791320    0.658537   \n",
       "94        Random Forest     over    roc_auc     0.791221    0.604688   \n",
       "80        Random Forest     none   accuracy     0.680534    0.653963   \n",
       "62                  SVM     none     recall     0.413356    0.328125   \n",
       "63                  SVM     none         f1     0.494267    0.423174   \n",
       "92        Random Forest     over     recall     0.793344    0.402344   \n",
       "86        Random Forest    under  precision     0.655839    0.557522   \n",
       "21                  KNN     none  precision     0.624408    0.633333   \n",
       "91        Random Forest     over  precision     0.797093    0.572327   \n",
       "98        Random Forest    smote         f1     0.696007    0.533066   \n",
       "81        Random Forest     none  precision     0.749144    0.661765   \n",
       "20                  KNN     none   accuracy     0.651908    0.641768   \n",
       "24                  KNN     none    roc_auc     0.586472    0.571250   \n",
       "93        Random Forest     over         f1     0.784080    0.444444   \n",
       "70                  SVM     over   accuracy     0.655573    0.640244   \n",
       "73                  SVM     over         f1     0.630907    0.504202   \n",
       "96        Random Forest    smote  precision     0.716992    0.541667   \n",
       "82        Random Forest     none     recall     0.354242    0.273438   \n",
       "83        Random Forest     none         f1     0.462250    0.370370   \n",
       "84        Random Forest     none    roc_auc     0.620489    0.571719   \n",
       "95        Random Forest    smote   accuracy     0.707775    0.635671   \n",
       "99        Random Forest    smote    roc_auc     0.707703    0.612656   \n",
       "85        Random Forest    under   accuracy     0.626716    0.635671   \n",
       "87        Random Forest    under     recall     0.613501    0.570312   \n",
       "88        Random Forest    under         f1     0.621883    0.549906   \n",
       "89        Random Forest    under    roc_auc     0.626719    0.623906   \n",
       "97        Random Forest    smote     recall     0.688873    0.500000   \n",
       "69                  SVM    under    roc_auc     0.618369    0.604453   \n",
       "75                  SVM    smote   accuracy     0.645840    0.623476   \n",
       "65                  SVM    under   accuracy     0.619576    0.621951   \n",
       "67                  SVM    under     recall     0.533943    0.445312   \n",
       "30                  KNN     over   accuracy     0.737816    0.621951   \n",
       "31                  KNN     over  precision     0.699669    0.515625   \n",
       "33                  KNN     over         f1     0.754461    0.515625   \n",
       "34                  KNN     over    roc_auc     0.737740    0.602812   \n",
       "42        Decision Tree     none     recall     0.324754    0.199219   \n",
       "43        Decision Tree     none         f1     0.410534    0.289773   \n",
       "40        Decision Tree     none   accuracy     0.646565    0.618902   \n",
       "44        Decision Tree     none    roc_auc     0.583459    0.544922   \n",
       "0   Logistic Regression     none   accuracy     0.611832    0.612805   \n",
       "1   Logistic Regression     none  precision     0.583333    1.000000   \n",
       "2   Logistic Regression     none     recall     0.010765    0.007812   \n",
       "3   Logistic Regression     none         f1     0.021017    0.015504   \n",
       "4   Logistic Regression     none    roc_auc     0.503507    0.503906   \n",
       "64                  SVM     none    roc_auc     0.504758    0.501953   \n",
       "41        Decision Tree     none  precision     0.690488    0.517241   \n",
       "77                  SVM    smote     recall     0.551125    0.574219   \n",
       "76                  SVM    smote  precision     0.663116    0.500000   \n",
       "78                  SVM    smote         f1     0.694003    0.527675   \n",
       "32                  KNN     over     recall     0.829034    0.539062   \n",
       "50        Decision Tree     over   accuracy     0.617962    0.609756   \n",
       "52        Decision Tree     over     recall     0.481781    0.339844   \n",
       "53        Decision Tree     over         f1     0.554950    0.404651   \n",
       "54        Decision Tree     over    roc_auc     0.617921    0.561172   \n",
       "71                  SVM     over  precision     1.000000    0.000000   \n",
       "47        Decision Tree    under     recall     0.423678    0.367188   \n",
       "48        Decision Tree    under         f1     0.486509    0.420582   \n",
       "72                  SVM     over     recall     0.694001    0.183594   \n",
       "74                  SVM     over    roc_auc     0.757012    0.526797   \n",
       "25                  KNN    under   accuracy     0.601777    0.600610   \n",
       "26                  KNN    under  precision     0.616656    0.488095   \n",
       "28                  KNN    under         f1     0.574503    0.484252   \n",
       "29                  KNN    under    roc_auc     0.601808    0.578984   \n",
       "37                  KNN    smote     recall     0.767175    0.601562   \n",
       "45        Decision Tree    under   accuracy     0.562119    0.596037   \n",
       "49        Decision Tree    under    roc_auc     0.562152    0.533750   \n",
       "35                  KNN    smote   accuracy     0.689308    0.594512   \n",
       "36                  KNN    smote  precision     0.662917    0.481203   \n",
       "38                  KNN    smote         f1     0.710226    0.490421   \n",
       "39                  KNN    smote    roc_auc     0.689269    0.577500   \n",
       "79                  SVM    smote    roc_auc     0.690559    0.531797   \n",
       "46        Decision Tree    under  precision     0.717972    0.409091   \n",
       "51        Decision Tree     over  precision     0.726401    0.464789   \n",
       "22                  KNN     none     recall     0.462846    0.390625   \n",
       "23                  KNN     none         f1     0.474962    0.423729   \n",
       "55        Decision Tree    smote   accuracy     0.598259    0.577744   \n",
       "56        Decision Tree    smote  precision     0.608493    0.468468   \n",
       "58        Decision Tree    smote         f1     0.581752    0.529711   \n",
       "59        Decision Tree    smote    roc_auc     0.598309    0.583438   \n",
       "27                  KNN    under     recall     0.556738    0.500000   \n",
       "61                  SVM     none  precision     0.379467    0.393617   \n",
       "66                  SVM    under  precision     0.524566    0.376033   \n",
       "5   Logistic Regression    under   accuracy     0.506363    0.501524   \n",
       "6   Logistic Regression    under  precision     0.508231    0.389408   \n",
       "7   Logistic Regression    under     recall     0.480473    0.488281   \n",
       "8   Logistic Regression    under         f1     0.493492    0.433276   \n",
       "9   Logistic Regression    under    roc_auc     0.506413    0.499141   \n",
       "15  Logistic Regression    smote   accuracy     0.503123    0.501524   \n",
       "16  Logistic Regression    smote  precision     0.502888    0.384365   \n",
       "17  Logistic Regression    smote     recall     0.478064    0.460938   \n",
       "18  Logistic Regression    smote         f1     0.490084    0.419183   \n",
       "19  Logistic Regression    smote    roc_auc     0.503108    0.494219   \n",
       "68                  SVM    under         f1     0.483935    0.440678   \n",
       "10  Logistic Regression     over   accuracy     0.507506    0.496951   \n",
       "11  Logistic Regression     over  precision     0.507809    0.385802   \n",
       "12  Logistic Regression     over     recall     0.484975    0.488281   \n",
       "13  Logistic Regression     over         f1     0.496022    0.431034   \n",
       "14  Logistic Regression     over    roc_auc     0.507504    0.495391   \n",
       "57        Decision Tree    smote     recall     0.577719    0.871094   \n",
       "\n",
       "    accuracy  precision    recall        f1   roc_auc  \\\n",
       "60  0.658537   0.686047  0.230469  0.345029  0.581484   \n",
       "90  0.658537   0.605263  0.359375  0.450980  0.604688   \n",
       "94  0.658537   0.605263  0.359375  0.450980  0.604688   \n",
       "80  0.653963   0.623932  0.285156  0.391421  0.587578   \n",
       "62  0.650915   0.595745  0.328125  0.423174  0.592812   \n",
       "63  0.650915   0.595745  0.328125  0.423174  0.592812   \n",
       "92  0.650915   0.575419  0.402344  0.473563  0.606172   \n",
       "86  0.649390   0.557522  0.492188  0.522822  0.621094   \n",
       "21  0.646341   0.633333  0.222656  0.329480  0.570078   \n",
       "91  0.644817   0.572327  0.355469  0.438554  0.592734   \n",
       "98  0.644817   0.547325  0.519531  0.533066  0.622266   \n",
       "81  0.643293   0.661765  0.175781  0.277778  0.559141   \n",
       "20  0.641768   0.598131  0.250000  0.352617  0.571250   \n",
       "24  0.641768   0.598131  0.250000  0.352617  0.571250   \n",
       "93  0.641768   0.562874  0.367188  0.444444  0.592344   \n",
       "70  0.640244   0.545455  0.468750  0.504202  0.609375   \n",
       "73  0.640244   0.545455  0.468750  0.504202  0.609375   \n",
       "96  0.640244   0.541667  0.507812  0.524194  0.616406   \n",
       "82  0.637195   0.573770  0.273438  0.370370  0.571719   \n",
       "83  0.637195   0.573770  0.273438  0.370370  0.571719   \n",
       "84  0.637195   0.573770  0.273438  0.370370  0.571719   \n",
       "95  0.635671   0.534979  0.507812  0.521042  0.612656   \n",
       "99  0.635671   0.534979  0.507812  0.521042  0.612656   \n",
       "85  0.635671   0.530909  0.570312  0.549906  0.623906   \n",
       "87  0.635671   0.530909  0.570312  0.549906  0.623906   \n",
       "88  0.635671   0.530909  0.570312  0.549906  0.623906   \n",
       "89  0.635671   0.530909  0.570312  0.549906  0.623906   \n",
       "97  0.631098   0.528926  0.500000  0.514056  0.607500   \n",
       "69  0.626524   0.522267  0.503906  0.512922  0.604453   \n",
       "75  0.623476   0.514754  0.613281  0.559715  0.621641   \n",
       "65  0.621951   0.518182  0.445312  0.478992  0.590156   \n",
       "67  0.621951   0.518182  0.445312  0.478992  0.590156   \n",
       "30  0.621951   0.515625  0.515625  0.515625  0.602812   \n",
       "31  0.621951   0.515625  0.515625  0.515625  0.602812   \n",
       "33  0.621951   0.515625  0.515625  0.515625  0.602812   \n",
       "34  0.621951   0.515625  0.515625  0.515625  0.602812   \n",
       "42  0.618902   0.531250  0.199219  0.289773  0.543359   \n",
       "43  0.618902   0.531250  0.199219  0.289773  0.543359   \n",
       "40  0.618902   0.530000  0.207031  0.297753  0.544766   \n",
       "44  0.617378   0.523810  0.214844  0.304709  0.544922   \n",
       "0   0.612805   1.000000  0.007812  0.015504  0.503906   \n",
       "1   0.612805   1.000000  0.007812  0.015504  0.503906   \n",
       "2   0.612805   1.000000  0.007812  0.015504  0.503906   \n",
       "3   0.612805   1.000000  0.007812  0.015504  0.503906   \n",
       "4   0.612805   1.000000  0.007812  0.015504  0.503906   \n",
       "64  0.611280   1.000000  0.003906  0.007782  0.501953   \n",
       "41  0.611280   0.517241  0.058594  0.105263  0.511797   \n",
       "77  0.609756   0.500000  0.574219  0.534545  0.603359   \n",
       "76  0.609756   0.500000  0.558594  0.527675  0.600547   \n",
       "78  0.609756   0.500000  0.558594  0.527675  0.600547   \n",
       "32  0.609756   0.500000  0.539062  0.518797  0.597031   \n",
       "50  0.609756   0.500000  0.339844  0.404651  0.561172   \n",
       "52  0.609756   0.500000  0.339844  0.404651  0.561172   \n",
       "53  0.609756   0.500000  0.339844  0.404651  0.561172   \n",
       "54  0.609756   0.500000  0.339844  0.404651  0.561172   \n",
       "71  0.609756   0.000000  0.000000  0.000000  0.500000   \n",
       "47  0.605183   0.492147  0.367188  0.420582  0.562344   \n",
       "48  0.605183   0.492147  0.367188  0.420582  0.562344   \n",
       "72  0.602134   0.474747  0.183594  0.264789  0.526797   \n",
       "74  0.602134   0.474747  0.183594  0.264789  0.526797   \n",
       "25  0.600610   0.488095  0.480469  0.484252  0.578984   \n",
       "26  0.600610   0.488095  0.480469  0.484252  0.578984   \n",
       "28  0.600610   0.488095  0.480469  0.484252  0.578984   \n",
       "29  0.600610   0.488095  0.480469  0.484252  0.578984   \n",
       "37  0.599085   0.488889  0.601562  0.539405  0.599531   \n",
       "45  0.596037   0.467153  0.250000  0.325700  0.533750   \n",
       "49  0.596037   0.467153  0.250000  0.325700  0.533750   \n",
       "35  0.594512   0.481203  0.500000  0.490421  0.577500   \n",
       "36  0.594512   0.481203  0.500000  0.490421  0.577500   \n",
       "38  0.594512   0.481203  0.500000  0.490421  0.577500   \n",
       "39  0.594512   0.481203  0.500000  0.490421  0.577500   \n",
       "79  0.594512   0.463235  0.246094  0.321429  0.531797   \n",
       "46  0.591463   0.409091  0.105469  0.167702  0.503984   \n",
       "51  0.586890   0.464789  0.386719  0.422175  0.550859   \n",
       "22  0.585366   0.462963  0.390625  0.423729  0.550312   \n",
       "23  0.585366   0.462963  0.390625  0.423729  0.550312   \n",
       "55  0.577744   0.468468  0.609375  0.529711  0.583438   \n",
       "56  0.577744   0.468468  0.609375  0.529711  0.583438   \n",
       "58  0.577744   0.468468  0.609375  0.529711  0.583438   \n",
       "59  0.577744   0.468468  0.609375  0.529711  0.583438   \n",
       "27  0.571646   0.455516  0.500000  0.476723  0.558750   \n",
       "61  0.518293   0.393617  0.433594  0.412639  0.503047   \n",
       "66  0.518293   0.376033  0.355469  0.365462  0.488984   \n",
       "5   0.501524   0.389408  0.488281  0.433276  0.499141   \n",
       "6   0.501524   0.389408  0.488281  0.433276  0.499141   \n",
       "7   0.501524   0.389408  0.488281  0.433276  0.499141   \n",
       "8   0.501524   0.389408  0.488281  0.433276  0.499141   \n",
       "9   0.501524   0.389408  0.488281  0.433276  0.499141   \n",
       "15  0.501524   0.384365  0.460938  0.419183  0.494219   \n",
       "16  0.501524   0.384365  0.460938  0.419183  0.494219   \n",
       "17  0.501524   0.384365  0.460938  0.419183  0.494219   \n",
       "18  0.501524   0.384365  0.460938  0.419183  0.494219   \n",
       "19  0.501524   0.384365  0.460938  0.419183  0.494219   \n",
       "68  0.496951   0.389222  0.507812  0.440678  0.498906   \n",
       "10  0.496951   0.385802  0.488281  0.431034  0.495391   \n",
       "11  0.496951   0.385802  0.488281  0.431034  0.495391   \n",
       "12  0.496951   0.385802  0.488281  0.431034  0.495391   \n",
       "13  0.496951   0.385802  0.488281  0.431034  0.495391   \n",
       "14  0.496951   0.385802  0.488281  0.431034  0.495391   \n",
       "57  0.472561   0.416045  0.871094  0.563131  0.544297   \n",
       "\n",
       "                                                                                                                          best_params  \n",
       "60                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "90  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "94  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "80     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}  \n",
       "62                                                                            {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "63                                                                            {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "92     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "86  {'rf__criterion': 'entropy', 'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}  \n",
       "21                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "91     {'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}  \n",
       "98  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}  \n",
       "81  {'rf__criterion': 'entropy', 'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}  \n",
       "20                                                                               {'knn__n_neighbors': 15, 'knn__weights': 'distance'}  \n",
       "24                                                                               {'knn__n_neighbors': 15, 'knn__weights': 'distance'}  \n",
       "93     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "70                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "73                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "96     {'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}  \n",
       "82     {'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "83     {'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "84     {'rf__criterion': 'gini', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "95  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "99  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "85     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "87     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "88     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "89     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}  \n",
       "97  {'rf__criterion': 'entropy', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}  \n",
       "69                                                                            {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "75                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "65                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "67                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "30                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "31                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "33                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "34                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "42                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "43                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "40                            {'dt__criterion': 'entropy', 'dt__max_depth': 9, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}  \n",
       "44                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 4, 'dt__min_samples_split': 2}  \n",
       "0                                                                                                                     {'lgr__C': 0.1}  \n",
       "1                                                                                                                     {'lgr__C': 0.1}  \n",
       "2                                                                                                                     {'lgr__C': 0.1}  \n",
       "3                                                                                                                     {'lgr__C': 0.1}  \n",
       "4                                                                                                                     {'lgr__C': 0.1}  \n",
       "64                                                                          {'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'poly'}  \n",
       "41                               {'dt__criterion': 'gini', 'dt__max_depth': 3, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "77                                                                           {'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "76                                                                            {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "78                                                                            {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "32                                                                               {'knn__n_neighbors': 13, 'knn__weights': 'distance'}  \n",
       "50                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "52                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "53                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "54                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "71                                                                            {'svm__C': 1, 'svm__gamma': 10.0, 'svm__kernel': 'rbf'}  \n",
       "47                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 3, 'dt__min_samples_split': 2}  \n",
       "48                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 3, 'dt__min_samples_split': 2}  \n",
       "72                                                                            {'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'rbf'}  \n",
       "74                                                                            {'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'rbf'}  \n",
       "25                                                                               {'knn__n_neighbors': 15, 'knn__weights': 'distance'}  \n",
       "26                                                                               {'knn__n_neighbors': 15, 'knn__weights': 'distance'}  \n",
       "28                                                                               {'knn__n_neighbors': 15, 'knn__weights': 'distance'}  \n",
       "29                                                                               {'knn__n_neighbors': 15, 'knn__weights': 'distance'}  \n",
       "37                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "45                            {'dt__criterion': 'entropy', 'dt__max_depth': 7, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}  \n",
       "49                            {'dt__criterion': 'entropy', 'dt__max_depth': 7, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}  \n",
       "35                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "36                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "38                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "39                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "79                                                                             {'svm__C': 1, 'svm__gamma': 1.0, 'svm__kernel': 'rbf'}  \n",
       "46                            {'dt__criterion': 'entropy', 'dt__max_depth': 1, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "51                            {'dt__criterion': 'entropy', 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 2}  \n",
       "22                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "23                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "55                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}  \n",
       "56                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}  \n",
       "58                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}  \n",
       "59                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 3}  \n",
       "27                                                                                 {'knn__n_neighbors': 1, 'knn__weights': 'uniform'}  \n",
       "61                                                                        {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'sigmoid'}  \n",
       "66                                                                         {'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'linear'}  \n",
       "5                                                                                                                   {'lgr__C': 0.001}  \n",
       "6                                                                                                                   {'lgr__C': 0.001}  \n",
       "7                                                                                                                   {'lgr__C': 0.001}  \n",
       "8                                                                                                                   {'lgr__C': 0.001}  \n",
       "9                                                                                                                   {'lgr__C': 0.001}  \n",
       "15                                                                                                                    {'lgr__C': 0.1}  \n",
       "16                                                                                                                    {'lgr__C': 0.1}  \n",
       "17                                                                                                                    {'lgr__C': 0.1}  \n",
       "18                                                                                                                    {'lgr__C': 0.1}  \n",
       "19                                                                                                                    {'lgr__C': 0.1}  \n",
       "68                                                                        {'svm__C': 10, 'svm__gamma': 1.0, 'svm__kernel': 'sigmoid'}  \n",
       "10                                                                                                                      {'lgr__C': 1}  \n",
       "11                                                                                                                      {'lgr__C': 1}  \n",
       "12                                                                                                                   {'lgr__C': 0.01}  \n",
       "13                                                                                                                      {'lgr__C': 1}  \n",
       "14                                                                                                                      {'lgr__C': 1}  \n",
       "57                            {'dt__criterion': 'entropy', 'dt__max_depth': 3, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_results_df = results_df.sort_values(by=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], ascending=False)\n",
    "display(sorted_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Top 5 Models with the highest scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sampling</th>\n",
       "      <th>scorer</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.679541</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.581484</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.791320</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.791221</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.680534</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.391421</td>\n",
       "      <td>0.587578</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.413356</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.650915</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.592812</td>\n",
       "      <td>{'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model sampling    scorer  train_score  test_score  accuracy  \\\n",
       "60            SVM     none  accuracy     0.679541    0.658537  0.658537   \n",
       "90  Random Forest     over  accuracy     0.791320    0.658537  0.658537   \n",
       "94  Random Forest     over   roc_auc     0.791221    0.604688  0.658537   \n",
       "80  Random Forest     none  accuracy     0.680534    0.653963  0.653963   \n",
       "62            SVM     none    recall     0.413356    0.328125  0.650915   \n",
       "\n",
       "    precision    recall        f1   roc_auc  \\\n",
       "60   0.686047  0.230469  0.345029  0.581484   \n",
       "90   0.605263  0.359375  0.450980  0.604688   \n",
       "94   0.605263  0.359375  0.450980  0.604688   \n",
       "80   0.623932  0.285156  0.391421  0.587578   \n",
       "62   0.595745  0.328125  0.423174  0.592812   \n",
       "\n",
       "                                                                                                                          best_params  \n",
       "60                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  \n",
       "90  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "94  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "80     {'rf__criterion': 'gini', 'rf__max_depth': 20, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}  \n",
       "62                                                                            {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_results_df = sorted_results_df.head(5)\n",
    "top_5_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best two performining models were:\n",
    "\n",
    "1. SVM with no sampling trained on accuracy\n",
    "    - accuracy: 0.659\n",
    "    - precision: 0.686\n",
    "    - roc_auc: 0.581\n",
    "2. Random Forest with oversampling trained on accuracy\n",
    "    - accuracy: 0.659\n",
    "    - precision: 0.605\n",
    "    - roc_auc: 0.605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Best Models of each Classifier Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sampling</th>\n",
       "      <th>scorer</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>none</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.324754</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.543359</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>none</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.624408</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.329480</td>\n",
       "      <td>0.570078</td>\n",
       "      <td>{'knn__n_neighbors': 21, 'knn__weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.611832</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>{'lgr__C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>over</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.791320</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.604688</td>\n",
       "      <td>{'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>none</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.679541</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.581484</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model sampling     scorer  train_score  test_score  accuracy  \\\n",
       "0        Decision Tree     none     recall     0.324754    0.199219  0.618902   \n",
       "1                  KNN     none  precision     0.624408    0.633333  0.646341   \n",
       "2  Logistic Regression     none   accuracy     0.611832    0.612805  0.612805   \n",
       "3        Random Forest     over   accuracy     0.791320    0.658537  0.658537   \n",
       "4                  SVM     none   accuracy     0.679541    0.658537  0.658537   \n",
       "\n",
       "   precision    recall        f1   roc_auc  \\\n",
       "0   0.531250  0.199219  0.289773  0.543359   \n",
       "1   0.633333  0.222656  0.329480  0.570078   \n",
       "2   1.000000  0.007812  0.015504  0.503906   \n",
       "3   0.605263  0.359375  0.450980  0.604688   \n",
       "4   0.686047  0.230469  0.345029  0.581484   \n",
       "\n",
       "                                                                                                                         best_params  \n",
       "0                               {'dt__criterion': 'gini', 'dt__max_depth': 9, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}  \n",
       "1                                                                               {'knn__n_neighbors': 21, 'knn__weights': 'distance'}  \n",
       "2                                                                                                                    {'lgr__C': 0.1}  \n",
       "3  {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}  \n",
       "4                                                                             {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_df = sorted_results_df.groupby('model').first().reset_index()\n",
    "best_models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature names\n",
    "\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance of the best random forest model\n",
    "\n",
    "rf_gs = joblib.load('../models/rf_gs_over_accuracy_.pkl')\n",
    "rf_feature_importance = rf_gs.best_estimator_.named_steps['rf'].feature_importances_\n",
    "\n",
    "rf_feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': rf_feature_importance})\n",
    "rf_feature_importance_df = rf_feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=rf_feature_importance_df, palette='viridis')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features are equally important for the best Random Forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance of the best SVM model\n",
    "\n",
    "svm_gs = joblib.load('../models/svm_gs_none_accuracy_.pkl')\n",
    "svm_perm_importance = permutation_importance(svm_gs.best_estimator_, X, y, n_repeats=10, random_state=42)\n",
    "svm_feature_importance = svm_perm_importance.importances_mean\n",
    "\n",
    "svm_feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': svm_feature_importance})\n",
    "svm_feature_importance_df = svm_feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=svm_feature_importance_df, palette='viridis')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sulfate and PH are the most important features for the best SVM classifier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
